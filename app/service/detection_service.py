# app/service/detection_service.py
import asyncio
import uuid
from datetime import datetime, timedelta
from typing import Dict, List

from fastapi import HTTPException, status

from app.cfg.config import AppSettings
from app.cfg.logging import app_logger
from app.core.pipeline import VideoStreamPipeline
from app.schema.detection_schema import ActiveStreamInfo, StreamStartRequest

from app.core.model_manager import model_pool


class DetectionService:
    """
    å°è£…æ ¸å¿ƒä¸šåŠ¡é€»è¾‘çš„æœåŠ¡ç±»ï¼ŒæŒæœ‰å¯¹ ModelPool çš„å¼•ç”¨ã€‚
    èŒè´£ï¼š
    1. ä½œä¸º VideoStreamPipeline å®ä¾‹çš„å·¥å‚å’Œç®¡ç†è€…ã€‚
    2. ç»´æŠ¤æ´»åŠ¨æµçš„çŠ¶æ€ï¼Œå¤„ç†APIè¯·æ±‚ã€‚
    3. åè°ƒåº”ç”¨çš„ç”Ÿå‘½å‘¨æœŸï¼ˆå¯åŠ¨ã€åœæ­¢ã€æ¸…ç†ï¼‰ã€‚
    """

    def __init__(self, settings: AppSettings):
        app_logger.info("æ­£åœ¨åˆå§‹åŒ– DetectionService (é€‚é… Hailo)...")  # æ›´æ–°æ—¥å¿—ä¿¡æ¯
        self.settings = settings
        self.model_pool = model_pool  # ç›´æ¥å¼•ç”¨ ModelPool å•ä¾‹
        self.active_streams: Dict[str, VideoStreamPipeline] = {}
        self.stream_lock = asyncio.Lock()

    async def start_stream(self, req: StreamStartRequest) -> ActiveStreamInfo:
        """å¯åŠ¨ä¸€ä¸ªæ–°çš„è§†é¢‘æµå¤„ç†ä»»åŠ¡ã€‚"""
        stream_id = str(uuid.uuid4())
        lifetime = req.lifetime_minutes if req.lifetime_minutes is not None else self.settings.app.stream_default_lifetime_minutes

        app_logger.info(f"å‡†å¤‡ä¸ºæµ {stream_id} å¯åŠ¨ä¸€ä¸ªæ–°çš„è§†é¢‘æµå¤„ç†æµæ°´çº¿ (å®ƒå°†ä»æ¨¡å‹æ± ä¸­è·å–æ¨¡å‹)...")

        async with self.stream_lock:
            if stream_id in self.active_streams:
                raise HTTPException(status_code=409, detail="Stream ID conflict.")

            # 1. åˆ›å»ºWebç«¯æ¶ˆè´¹çš„å¼‚æ­¥é˜Ÿåˆ—
            frame_queue = asyncio.Queue(maxsize=self.settings.app.stream_max_queue_size)

            # 2. å®ä¾‹åŒ–å®Œæ•´çš„å¤„ç†æµæ°´çº¿
            pipeline = VideoStreamPipeline(
                settings=self.settings,
                stream_id=stream_id,
                video_source=req.source,
                output_queue=frame_queue
            )

            # 3. åœ¨çº¿ç¨‹æ± ä¸­å¯åŠ¨æµæ°´çº¿ï¼ˆè¿™æ˜¯ä¸€ä¸ªé˜»å¡æ“ä½œï¼‰
            loop = asyncio.get_running_loop()
            try:
                # pipeline.start() å†…éƒ¨ä¼š acquire æ¨¡å‹
                await loop.run_in_executor(None, pipeline.start)
            except Exception as e:
                app_logger.error(f"å¯åŠ¨è§†é¢‘æµ {stream_id} å¤±è´¥: {e}", exc_info=True)
                raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=f"æ— æ³•å¯åŠ¨è§†é¢‘æµï¼š{e}")

            # 4. è®°å½•æ–°æµçš„ä¿¡æ¯
            self.active_streams[stream_id] = pipeline
            started_at = datetime.now()
            expires_at = None if lifetime == -1 else started_at + timedelta(minutes=lifetime)
            stream_info = ActiveStreamInfo(stream_id=stream_id, source=req.source, started_at=started_at,
                                           expires_at=expires_at, lifetime_minutes=lifetime)

            setattr(pipeline, 'info', stream_info)  # è®°å½• info åˆ° pipeline å¯¹è±¡ä¸Š

            app_logger.info(f"ğŸš€ è§†é¢‘æµå¤„ç†æµæ°´çº¿å·²å¯åŠ¨: ID={stream_id}, æº={req.source}")
            return stream_info

    async def stop_stream(self, stream_id: str) -> bool:
        """åœæ­¢ä¸€ä¸ªæŒ‡å®šçš„è§†é¢‘æµã€‚"""
        async with self.stream_lock:
            pipeline = self.active_streams.pop(stream_id, None)
            if not pipeline:
                app_logger.warning(f"å°è¯•åœæ­¢ä¸€ä¸ªä¸å­˜åœ¨æˆ–å·²è¢«åœæ­¢çš„æµ: {stream_id}")
                return False

        # åœ¨çº¿ç¨‹æ± ä¸­åœæ­¢æµæ°´çº¿ï¼ˆè¿™æ˜¯ä¸€ä¸ªé˜»å¡æ“ä½œï¼‰ï¼Œpipeline.stop() å†…éƒ¨ä¼š release æ¨¡å‹
        loop = asyncio.get_running_loop()
        await loop.run_in_executor(None, pipeline.stop)

        app_logger.info(f"âœ… è§†é¢‘æµæµæ°´çº¿å·²è¯·æ±‚åœæ­¢: ID={stream_id}")
        return True

    async def get_stream_feed(self, stream_id: str):
        """[å‰å°åç¨‹] - ä»æŒ‡å®šæµæ°´çº¿çš„è¾“å‡ºé˜Ÿåˆ—è·å–å¸§ã€‚"""
        async with self.stream_lock:
            pipeline = self.active_streams.get(stream_id)

        if not pipeline:
            app_logger.warning(f"å®¢æˆ·ç«¯å°è¯•è¿æ¥ä¸€ä¸ªä¸å­˜åœ¨æˆ–å·²åœæ­¢çš„æµ: {stream_id}")
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Stream not found or already stopped.")

        frame_queue = pipeline.output_queue
        try:
            while True:
                # é˜»å¡è·å–å¸§ï¼Œç›´åˆ°æœ‰å¸§å¯ç”¨æˆ–æ”¶åˆ°ç»ˆæ­¢ä¿¡å·
                frame_bytes = await frame_queue.get()
                if frame_bytes is None:
                    app_logger.info(f"æ¥æ”¶åˆ°æµ {stream_id} çš„ç»ˆæ­¢ä¿¡å·ï¼Œæ­£å¸¸å…³é—­æ¨é€ã€‚")
                    break
                yield (b'--frame\r\n'
                       b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
                frame_queue.task_done()
        except asyncio.CancelledError:
            app_logger.info(f"å®¢æˆ·ç«¯ä»æµ {stream_id} æ–­å¼€ï¼Œå°†è‡ªåŠ¨åœæ­¢è¯¥æµã€‚")
            await self.stop_stream(stream_id)  # å®¢æˆ·ç«¯æ–­å¼€æ—¶è‡ªåŠ¨åœæ­¢æµ
            raise
        except Exception as e:
            app_logger.error(f"è·å–æµ {stream_id} é¦ˆé€æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            await self.stop_stream(stream_id)  # å‘ç”Ÿé”™è¯¯æ—¶åœæ­¢æµ
            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="æµå¤„ç†å¼‚å¸¸ï¼Œå·²åœæ­¢ã€‚")

    async def get_all_active_streams_info(self) -> List[ActiveStreamInfo]:
        """è·å–æ‰€æœ‰å½“å‰æ´»åŠ¨æµçš„ä¿¡æ¯åˆ—è¡¨ã€‚"""
        async with self.stream_lock:
            # è¿‡æ»¤æ‰æ²¡æœ‰ info å±æ€§çš„ï¼ˆç†è®ºä¸Šä¸åº”è¯¥æœ‰ï¼‰æˆ–è€…çº¿ç¨‹å·²æ­»çš„ç®¡é“
            active_pipelines = [p for p in self.active_streams.values() if
                                hasattr(p, 'info') and (p.threads and p.threads[0].is_alive())]
            return [getattr(p, 'info') for p in active_pipelines]

    async def cleanup_expired_streams(self):
        """[åå°ä»»åŠ¡] - å®šæœŸæ£€æŸ¥å¹¶æ¸…ç†æ‰€æœ‰å·²è¿‡æœŸçš„è§†é¢‘æµã€‚"""
        while True:
            await asyncio.sleep(self.settings.app.stream_cleanup_interval_seconds)
            now = datetime.now()
            expired_stream_ids = []
            async with self.stream_lock:
                # éå† active_streams çš„å‰¯æœ¬ï¼Œä»¥é¿å…åœ¨è¿­ä»£æ—¶ä¿®æ”¹å­—å…¸
                for stream_id, pipeline in list(self.active_streams.items()):
                    info = getattr(pipeline, 'info', None)
                    # æ£€æŸ¥æµæ˜¯å¦è¿‡æœŸï¼Œæˆ–è€…ç®¡é“çº¿ç¨‹æ˜¯å¦å·²æ„å¤–åœæ­¢
                    if (info and info.expires_at and now >= info.expires_at) or \
                            (pipeline.threads and not pipeline.threads[
                                0].is_alive() and not pipeline.stop_event.is_set()):
                        app_logger.warning(f"æ£€æµ‹åˆ°æµ {stream_id} è¿‡æœŸæˆ–å·²æ„å¤–åœæ­¢ï¼Œå‡†å¤‡æ¸…ç†ã€‚")
                        expired_stream_ids.append(stream_id)

            if expired_stream_ids:
                app_logger.info(f"ğŸ—‘ï¸ å‘ç° {len(expired_stream_ids)} ä¸ªè¿‡æœŸ/å¼‚å¸¸è§†é¢‘æµï¼Œæ­£åœ¨æ¸…ç†: {expired_stream_ids}")
                cleanup_tasks = [self.stop_stream(stream_id) for stream_id in expired_stream_ids]
                await asyncio.gather(*cleanup_tasks)

    async def stop_all_streams(self):
        """åœ¨åº”ç”¨å…³é—­æ—¶ï¼Œåœæ­¢æ‰€æœ‰æ´»åŠ¨çš„è§†é¢‘æµã€‚"""
        app_logger.info("åº”ç”¨å‡†å¤‡å…³é—­ï¼Œæ­£åœ¨åœæ­¢æ‰€æœ‰æ´»åŠ¨çš„è§†é¢‘æµ...")
        async with self.stream_lock:
            all_stream_ids = list(self.active_streams.keys())
        if all_stream_ids:
            stop_tasks = [self.stop_stream(stream_id) for stream_id in all_stream_ids]
            await asyncio.gather(*stop_tasks)
            app_logger.info(f"âœ… æ‰€æœ‰ {len(all_stream_ids)} ä¸ªæ´»åŠ¨æµå·²æ¸…ç†å®Œæ¯•ã€‚")