import cv2
import numpy as np
import onnxruntime as ort
import sys

class YOLO_ONNX_Detector:
    def __init__(self, onnx_path, classes, use_gpu=True, conf_threshold=0.5, iou_threshold=0.5):
        """
        åˆå§‹åŒ–YOLO ONNXæ¨ç†å™¨

        :param onnx_path: ONNXæ¨¡å‹çš„è·¯å¾„
        :param classes: ç±»åˆ«åç§°åˆ—è¡¨, ä¾‹å¦‚ ['smoke', 'fire']
        :param use_gpu: æ˜¯å¦ä¼˜å…ˆå°è¯•ä½¿ç”¨GPU
        :param conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        :param iou_threshold: NMSçš„IOUé˜ˆå€¼
        """
        self.onnx_path = onnx_path
        self.classes = classes
        self.conf_threshold = conf_threshold
        self.iou_threshold = iou_threshold

        # --- è‡ªåŠ¨è®¾å¤‡é€‰æ‹© (GPU/CPU) ---
        providers = ort.get_available_providers()
        chosen_provider = None

        if use_gpu and 'CUDAExecutionProvider' in providers:
            # å¦‚æœç”¨æˆ·å¸Œæœ›ä½¿ç”¨GPUä¸”CUDAå¯ç”¨
            chosen_provider = ['CUDAExecutionProvider', 'CPUExecutionProvider']
            print("âœ… æ£€æµ‹åˆ°CUDAï¼Œå°†ä¼˜å…ˆä½¿ç”¨GPUè¿›è¡Œæ¨ç†ã€‚")
        else:
            # å¦åˆ™ï¼Œä½¿ç”¨CPU
            chosen_provider = ['CPUExecutionProvider']
            if use_gpu: # ä»…å½“ç”¨æˆ·æ„å›¾ä½¿ç”¨GPUä½†ä¸å¯ç”¨æ—¶å‘å‡ºè­¦å‘Š
                print("âš ï¸ è­¦å‘Š: æœªæ£€æµ‹åˆ°å¯ç”¨çš„CUDAè®¾å¤‡æˆ–ONNX RuntimeéGPUç‰ˆæœ¬ã€‚å°†è‡ªåŠ¨åˆ‡æ¢åˆ°CPUè¿›è¡Œæ¨ç†ã€‚")
            else:
                print("â„¹ï¸ å·²é…ç½®ä¸ºä½¿ç”¨CPUè¿›è¡Œæ¨ç†ã€‚")
        
        # åŠ è½½ONNXæ¨¡å‹å¹¶åˆ›å»ºæ¨ç†ä¼šè¯
        try:
            self.session = ort.InferenceSession(self.onnx_path, providers=chosen_provider)
            # ç¡®è®¤å®é™…ä½¿ç”¨çš„è®¾å¤‡
            actual_provider = self.session.get_providers()[0]
            print(f"âœ… ONNX Runtime æ¨ç†å™¨åˆå§‹åŒ–æˆåŠŸï¼Œå½“å‰ä½¿ç”¨è®¾å¤‡: {actual_provider}")
        except Exception as e:
            print(f"âŒ é”™è¯¯: ONNXæ¨¡å‹åŠ è½½å¤±è´¥ã€‚è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®: {self.onnx_path}")
            print(f"é”™è¯¯è¯¦æƒ…: {e}")
            sys.exit(1) # æ¨¡å‹åŠ è½½å¤±è´¥åˆ™é€€å‡ºç¨‹åº

        # è·å–æ¨¡å‹è¾“å…¥ä¿¡æ¯
        model_input = self.session.get_inputs()[0]
        self.input_name = model_input.name
        self.input_shape = model_input.shape  # ä¾‹å¦‚ [1, 3, 640, 640]
        self.input_height = self.input_shape[2]
        self.input_width = self.input_shape[3]

    def _preprocess(self, image):
        """å¯¹è¾“å…¥å›¾åƒè¿›è¡Œé¢„å¤„ç† (Letterbox)"""
        img_h, img_w, _ = image.shape

        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œå¹¶ä¿æŒå®½é«˜æ¯”
        scale = min(self.input_width / img_w, self.input_height / img_h)
        new_w, new_h = int(img_w * scale), int(img_h * scale)

        # ç¼©æ”¾å›¾åƒ
        resized_img = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)

        # åˆ›å»ºä¸€ä¸ªç°è‰²ç”»å¸ƒï¼Œå¹¶å°†ç¼©æ”¾åçš„å›¾åƒç²˜è´´åˆ°ä¸­å¿ƒ
        padded_img = np.full((self.input_height, self.input_width, 3), 114, dtype=np.uint8)
        dw, dh = (self.input_width - new_w) // 2, (self.input_height - new_h) // 2
        padded_img[dh:dh + new_h, dw:dw + new_w, :] = resized_img

        # è½¬æ¢ BGR -> RGB, HWC -> CHW, å½’ä¸€åŒ–
        img_rgb = padded_img[:, :, ::-1]
        img_transposed = np.transpose(img_rgb, (2, 0, 1))
        img_normalized = img_transposed.astype(np.float32) / 255.0

        # å¢åŠ batchç»´åº¦
        input_tensor = np.expand_dims(img_normalized, axis=0)

        return input_tensor, scale, dw, dh

    def _postprocess(self, output, scale, dw, dh):
        """å¯¹æ¨¡å‹è¾“å‡ºè¿›è¡Œåå¤„ç†"""
        # Ultralyticså¯¼å‡ºçš„ONNXè¾“å‡ºå½¢çŠ¶é€šå¸¸æ˜¯ [1, 6, 8400] -> [batch, 4_bbox+num_classes, num_proposals]
        # æˆ‘ä»¬éœ€è¦å°†å…¶è½¬ç½®ä¸º [1, 8400, 6]
        predictions = np.squeeze(output).T

        # è¿‡æ»¤æ‰ç½®ä¿¡åº¦ä½çš„æ£€æµ‹ç»“æœ
        # è·å–æ‰€æœ‰æ¡†ä¸­ï¼Œæ¯ä¸ªç±»åˆ«çš„æœ€é«˜åˆ†
        scores = np.max(predictions[:, 4:], axis=1)
        predictions = predictions[scores > self.conf_threshold, :]
        scores = scores[scores > self.conf_threshold]

        if predictions.shape[0] == 0:
            return [], [], []

        # è·å–ç±»åˆ«ID
        class_ids = np.argmax(predictions[:, 4:], axis=1)

        # å°† (x_center, y_center, w, h) æ ¼å¼çš„æ¡†è½¬æ¢ä¸º (x1, y1, x2, y2)
        boxes = self._xywh2xyxy(predictions[:, :4])

        # è°ƒæ•´åæ ‡ä»¥åŒ¹é…åŸå§‹å›¾åƒå°ºå¯¸
        boxes -= np.array([dw, dh, dw, dh])
        boxes /= scale

        # åº”ç”¨éæå¤§å€¼æŠ‘åˆ¶ (NMS)
        indices = cv2.dnn.NMSBoxes(boxes.tolist(), scores.tolist(), self.conf_threshold, self.iou_threshold)

        # æå–æœ€ç»ˆç»“æœ
        final_boxes = boxes[indices]
        final_scores = scores[indices]
        final_class_ids = class_ids[indices]

        return final_boxes, final_scores, final_class_ids

    def _xywh2xyxy(self, xywh):
        """(x_center, y_center, w, h) -> (x1, y1, x2, y2)"""
        xy, wh = xywh[:, 0:2], xywh[:, 2:4]
        xy1 = xy - wh / 2
        xy2 = xy + wh / 2
        return np.concatenate([xy1, xy2], axis=1)

    def draw_detections(self, image, boxes, scores, class_ids):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ"""
        for box, score, class_id in zip(boxes, scores, class_ids):
            x1, y1, x2, y2 = box.astype(int)
            label = f"{self.classes[class_id]}: {score:.2f}"
            
            # fireä¸ºçº¢è‰², smokeä¸ºç»¿è‰²
            color = (0, 0, 255) if self.classes[class_id] == 'fire' else (0, 255, 0)
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        return image

    def detect(self, image_path):
        """
        æ‰§è¡Œå®Œæ•´çš„æ£€æµ‹æµç¨‹
        :param image_path: è¾“å…¥å›¾åƒçš„è·¯å¾„
        :return: å¸¦æœ‰æ£€æµ‹ç»“æœçš„å›¾åƒ
        """
        original_image = cv2.imread(image_path)
        if original_image is None:
            print(f"âŒ é”™è¯¯: æ— æ³•è¯»å–å›¾ç‰‡ {image_path}")
            return None

        # é¢„å¤„ç†
        input_tensor, scale, dw, dh = self._preprocess(original_image)

        # æ‰§è¡Œæ¨ç†
        outputs = self.session.run(None, {self.input_name: input_tensor})

        # åå¤„ç†
        boxes, scores, class_ids = self._postprocess(outputs[0], scale, dw, dh)

        # ç»˜åˆ¶ç»“æœ
        result_image = self.draw_detections(original_image, boxes, scores, class_ids)

        return result_image

if __name__ == '__main__':
    # --- é…ç½®å‚æ•° ---
    ONNX_MODEL_PATH = "smoke_fire_s.onnx"
    IMAGE_PATH = "./test.png"  # <<-- æ›¿æ¢ä¸ºä½ çš„æµ‹è¯•å›¾ç‰‡è·¯å¾„
    CLASSES = ['smoke', 'fire']  # <<-- ä½ çš„ç±»åˆ«ï¼Œé¡ºåºå¿…é¡»å’Œè®­ç»ƒæ—¶ä¸€è‡´
    OUTPUT_IMAGE_PATH = "result_onnx.jpg"
    USE_GPU = True # <<-- åœ¨æ­¤è®¾ç½®æ˜¯å¦ä¼˜å…ˆä½¿ç”¨GPU

    # --- æ‰§è¡Œæ£€æµ‹ ---
    print("ğŸš€ å¼€å§‹è¿›è¡ŒONNXæ¨¡å‹æ¨ç†...")

    # 1. æ£€æŸ¥ä¾èµ– (å¯é€‰ï¼Œä½†æ¨è)
    try:
        import onnxruntime
    except ImportError:
        print("âŒ é”™è¯¯: onnxruntime æœªå®‰è£…ã€‚è¯·è¿è¡Œ 'pip install onnxruntime-gpu' (æ¨è) æˆ– 'pip install onnxruntime'ã€‚")
        sys.exit(1)

    # 2. åˆå§‹åŒ–æ£€æµ‹å™¨ (å†…éƒ¨å·²åŒ…å«è®¾å¤‡æ£€æµ‹å’Œæ¨¡å‹åŠ è½½)
    detector = YOLO_ONNX_Detector(
        onnx_path=ONNX_MODEL_PATH, 
        classes=CLASSES,
        use_gpu=USE_GPU
    )

    # 3. å¯¹å•å¼ å›¾ç‰‡è¿›è¡Œæ£€æµ‹
    print(f"\nğŸ” æ­£åœ¨æ£€æµ‹å›¾ç‰‡: {IMAGE_PATH}")
    result_img = detector.detect(image_path=IMAGE_PATH)

    # 4. ä¿å­˜æˆ–æ˜¾ç¤ºç»“æœ
    if result_img is not None:
        cv2.imwrite(OUTPUT_IMAGE_PATH, result_img)
        print(f"âœ… æ£€æµ‹å®Œæˆ! ç»“æœå·²ä¿å­˜è‡³: {OUTPUT_IMAGE_PATH}")
        # å¦‚æœä½ æƒ³ç›´æ¥æ˜¾ç¤ºå›¾ç‰‡ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢çš„æ³¨é‡Š
        # cv2.imshow("ONNX Detection Result", result_img)
        # cv2.waitKey(0)
        # cv2.destroyAllWindows()